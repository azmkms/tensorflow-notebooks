{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7  8  9  "
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  0  1  2  3  4  "
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "dataset = dataset.repeat(2)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7  8  9  "
     ]
    }
   ],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)    # Take a placeholder to create a dataset\n",
    "iterator = dataset.make_initializable_iterator()      # Create an initializable iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize an iterator over a dataset with 10 elements using placeholder.\n",
    "    sess.run(iterator.initializer, feed_dict={max_value: 10}) \n",
    "\n",
    "    for _ in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  \n",
      "\n",
      "0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.range(10)\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# Build an iterator that can take different datasets with the same type and shape\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Get 2 init op for 2 different dataset\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(2):\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            value = sess.run(next_element)\n",
    "            print(f\"{value} \", end=\" \")\n",
    "\n",
    "        sess.run(validation_init_op)\n",
    "        for _ in range(5):\n",
    "            value = sess.run(next_element)\n",
    "            print(f\"{value} \", end=\" \")\n",
    "            \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  \n",
      "\n",
      "10  11  12  13  14  15  16  17  18  19  0  1  2  3  4  \n",
      "\n",
      "20  21  22  23  24  25  26  27  28  29  0  1  2  3  4  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 2 dataset witht the same datatype and shape\n",
    "training_dataset = tf.data.Dataset.range(30)\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# Create a feedable iterator that use a placeholder to switch between dataset\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Create 2 iterators\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Return handles that can be feed as the iterator in sess.run\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "\n",
    "    for _ in range(3):\n",
    "        for _ in range(10):\n",
    "            value = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            print(f\"{value} \", end=\" \")\n",
    "\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            value = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "            print(f\"{value} \", end=\" \")\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09447801 0.5290395  0.46006417 0.03894734 0.470865   0.28260875\n",
      " 0.5192795  0.59933877 0.7981429  0.3622675 ] \n",
      "[0.36460412 0.46807122 0.3752532  0.70037234 0.19405639 0.8199223\n",
      " 0.03183115 0.19940841 0.48549366 0.4922037 ] \n",
      "[0.66499364 0.06752551 0.06007934 0.70466506 0.00995421 0.72531235\n",
      " 0.64778054 0.63643646 0.18187034 0.01640058] \n",
      "[0.14747453 0.7501242  0.03595364 0.8796506  0.03570914 0.98773813\n",
      " 0.16869736 0.9395461  0.85256135 0.7036263 ] \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()      # Create an initializable iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "\n",
    "    for i in range(4):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \")        # Print out an array with 10 random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5518974, array([83, 41, 96, 56, 26, 10,  7, 88, 21, 91, 11, 87, 10, 39, 63, 85, 26,\n",
      "       56, 63, 19, 93, 15, 28, 52, 65, 59,  3, 40, 69, 15, 50, 28, 73, 97,\n",
      "       87, 81, 86,  7,  8, 84, 61, 74, 77, 71, 20, 57, 98, 15, 71, 85, 49,\n",
      "       93,  6, 94, 13, 47, 80, 78, 24, 52, 52, 20, 54, 88, 68, 38, 80, 80,\n",
      "        0, 66, 86,  8, 99, 57,  8, 41, 83, 66, 66, 59, 83, 90, 72, 29, 62,\n",
      "       62, 20,  0,  2, 51, 71, 92, 97, 11, 72,  6, 35, 73, 30, 91],\n",
      "      dtype=int32)) \n",
      "(0.20816946, array([43, 80, 61, 74, 31, 34, 46, 74, 98, 38, 71,  7, 69, 45, 84, 38, 28,\n",
      "       35,  0, 56, 73, 49, 13,  5, 66, 57, 36, 64, 61, 24, 62,  5, 99, 41,\n",
      "        1, 23, 89,  3, 16, 64, 65, 11, 50, 74, 38,  9, 21, 50, 92, 42, 30,\n",
      "        4, 72, 44, 39, 42, 85, 60, 60, 57, 88,  3, 70, 47, 20, 61, 90, 66,\n",
      "       88, 76, 49,  3, 64, 44, 94, 82, 24,  5, 38, 21, 17, 61, 17, 80, 69,\n",
      "       65, 72, 78, 54, 73, 10, 80, 81, 88, 25, 82,  1, 81,  7, 83],\n",
      "      dtype=int32)) \n",
      "(0.98128736, array([30, 16, 81, 77, 79, 69, 30,  1, 62,  4, 31, 27, 16, 52,  6, 54, 28,\n",
      "       98, 72, 58, 78, 24, 45, 80, 71, 46, 38, 58, 91,  4, 33, 83, 79, 81,\n",
      "       83, 60, 23,  8, 60, 43, 65, 57, 50, 58, 75, 86, 81, 74,  8, 74,  0,\n",
      "       96, 32, 36, 75,  7,  0, 81, 30, 11, 14, 55, 14, 44, 80, 63, 29, 43,\n",
      "       18, 16, 13, 71, 34, 25, 67, 41, 78, 74, 25, 82, 99, 21, 77, 51, 88,\n",
      "       61,  6,  8, 20,  2, 99,  2, 94,  4, 42,  2, 83, 22,  7, 76],\n",
      "      dtype=int32)) \n",
      "(0.010109782, array([12, 20, 47, 83, 74, 65, 86, 86, 64, 54, 19, 35, 46,  2, 68, 13, 25,\n",
      "       39, 56, 62, 39,  8, 30, 80, 59, 52, 89, 89, 24,  0, 43, 75, 91, 74,\n",
      "       98, 57, 46, 47, 30, 34, 31, 41, 66, 84, 89, 47,  2, 25, 90, 63, 63,\n",
      "       69, 80,  0, 89, 23, 35,  1, 12, 48, 43, 75, 31, 74, 76, 99, 29, 80,\n",
      "       96, 24, 19, 44, 92, 32, 58, 50, 50,  3, 90, 21,  8, 46, 99, 18, 52,\n",
      "       96, 27, 39, 53, 70, 70, 46, 41, 91, 93, 64, 96,  7, 42, 14],\n",
      "      dtype=int32)) \n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random_uniform([4]),                                   # (tf.float32, tf.int32)\n",
    "     tf.random_uniform([4, 100], maxval=100, dtype=tf.int32))) # ((), (100,))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()      # Create an initializable iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "\n",
    "    for i in range(4):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \")        # Print out an array with 10 random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.int32)\n",
      "(TensorShape([]), TensorShape([Dimension(100)]))\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random_uniform([4]),                                   # (tf.float32, tf.int32)\n",
    "     tf.random_uniform([4, 100], maxval=100, dtype=tf.int32))) # ((), (100,))\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tf.float32, 'b': tf.int32}\n",
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\"a\": tf.random_uniform([4]),\n",
    "     \"b\": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})\n",
    "print(dataset.output_types)  # ==> \"{'a': tf.float32, 'b': tf.int32}\"\n",
    "print(dataset.output_shapes) # ==> \"{'a': (), 'b': (100,)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0,US,\"This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022\\xe2\\x80\\x932030.\",Martha\\'s Vineyard,96,235.0,California,Napa Valley,Napa,Cabernet Sauvignon,Heitz'\n",
      "b'1,Spain,\"Ripe aromas of fig, blackberry and cassis are softened and sweetened by a slathering of oaky chocolate and vanilla. This is full, layered, intense and cushioned on the palate, with rich flavors of chocolaty black fruits and baking spices. A toasty, everlasting finish is heady but ideally balanced. Drink through 2023.\",Carodorum Selecci\\xc3\\xb3n Especial Reserva,96,110.0,Northern Spain,Toro,,Tinta de Toro,Bodega Carmen Rodr\\xc3\\xadguez'\n"
     ]
    }
   ],
   "source": [
    "filenames = [\"wine_data.csv\"]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "dataset = dataset.flat_map(\n",
    "    lambda filename: (\n",
    "        tf.data.TextLineDataset(filename)\n",
    "        .skip(1)\n",
    "        ))\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(2):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0,US,\"This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022\\xe2\\x80\\x932030.\",Martha\\'s Vineyard,96,235.0,California,Napa Valley,Napa,Cabernet Sauvignon,Heitz'\n",
      "b'1,Spain,\"Ripe aromas of fig, blackberry and cassis are softened and sweetened by a slathering of oaky chocolate and vanilla. This is full, layered, intense and cushioned on the palate, with rich flavors of chocolaty black fruits and baking spices. A toasty, everlasting finish is heady but ideally balanced. Drink through 2023.\",Carodorum Selecci\\xc3\\xb3n Especial Reserva,96,110.0,Northern Spain,Toro,,Tinta de Toro,Bodega Carmen Rodr\\xc3\\xadguez'\n"
     ]
    }
   ],
   "source": [
    "filename = \"wine_data.csv\"\n",
    "\n",
    "dataset = (\n",
    "        tf.data.TextLineDataset(filename)\n",
    "        .skip(1)\n",
    "        )\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(2):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expect 12 fields but have 11 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9, DecodeCSV/record_defaults_10, DecodeCSV/record_defaults_11)]]\n\t [[Node: IteratorGetNext_17 = IteratorGetNext[output_shapes=[[], [], [], [], [], [], [], [], [], [], [], []], output_types=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_12)]]\n\nCaused by op 'DecodeCSV', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-08593d2dc13c>\", line 4, in <module>\n    col1, col2 = tf.decode_csv(value, record_defaults=[[0], [0]])\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1215, in decode_csv\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 68, in decode_csv\n    na_value=na_value, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Expect 12 fields but have 11 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9, DecodeCSV/record_defaults_10, DecodeCSV/record_defaults_11)]]\n\t [[Node: IteratorGetNext_17 = IteratorGetNext[output_shapes=[[], [], [], [], [], [], [], [], [], [], [], []], output_types=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_12)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expect 12 fields but have 11 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9, DecodeCSV/record_defaults_10, DecodeCSV/record_defaults_11)]]\n\t [[Node: IteratorGetNext_17 = IteratorGetNext[output_shapes=[[], [], [], [], [], [], [], [], [], [], [], []], output_types=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_12)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1dc6ac15fb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{value}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expect 12 fields but have 11 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9, DecodeCSV/record_defaults_10, DecodeCSV/record_defaults_11)]]\n\t [[Node: IteratorGetNext_17 = IteratorGetNext[output_shapes=[[], [], [], [], [], [], [], [], [], [], [], []], output_types=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_12)]]\n\nCaused by op 'DecodeCSV', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-08593d2dc13c>\", line 4, in <module>\n    col1, col2 = tf.decode_csv(value, record_defaults=[[0], [0]])\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1215, in decode_csv\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 68, in decode_csv\n    na_value=na_value, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Expect 12 fields but have 11 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9, DecodeCSV/record_defaults_10, DecodeCSV/record_defaults_11)]]\n\t [[Node: IteratorGetNext_17 = IteratorGetNext[output_shapes=[[], [], [], [], [], [], [], [], [], [], [], []], output_types=[DT_INT32, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_12)]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"wine_data.csv\"\n",
    "\n",
    "def decode_csv(line):\n",
    "    record_defaults = [[0], [\"\"], [\"\"], [\"\"], [\"\"], [0], [0.], [\"\"], [\"\"], [\"\"], [\"\"], [\"\"]]\n",
    "    parsed_line = tf.decode_csv(line, record_defaults)\n",
    "    #label = parsed_line[-1:] # Last element is the label\n",
    "    #del parsed_line[-1] # Delete last element\n",
    "    #features = parsed_line # Everything (but last element) are the features\n",
    "    #d = dict(zip(feature_names, features)), label\n",
    "    return parsed_line\n",
    "\n",
    "dataset = (\n",
    "        tf.data.TextLineDataset(filename)\n",
    "        .skip(1)\n",
    "        .map(decode_csv)\n",
    "        )\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(2):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
