{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "\n",
    "print(\"TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wine_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some preprocessing to limit the # of wine varities in the dataset\n",
    "data = data[pd.notnull(data['country'])]\n",
    "data = data[pd.notnull(data['price'])]\n",
    "data = data.drop(data.columns[0], axis=1) \n",
    "\n",
    "variety_threshold = 500 # Anything that occurs less than this will be removed.\n",
    "value_counts = data['variety'].value_counts()\n",
    "to_remove = value_counts[value_counts <= variety_threshold].index\n",
    "data.replace(to_remove, np.nan, inplace=True)\n",
    "data = data[pd.notnull(data['variety'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = data[['description','variety']] # features\n",
    "y = data['price']                   # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words vocabulary for description\n",
    "vocab_size = 12000\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
    "tokenize.fit_on_texts(X_train['description']) # only fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words vectors for train and test\n",
    "description_bow_train = tokenize.texts_to_matrix(X_train['description'])\n",
    "description_bow_test = tokenize.texts_to_matrix(X_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(X_train['variety']) # only fit on train\n",
    "variety_train = encoder.transform(X_train['variety'])\n",
    "variety_test = encoder.transform(X_test['variety'])\n",
    "num_classes = np.max(variety_train) + 1\n",
    "\n",
    "# Convert index to one hot\n",
    "variety_train = keras.utils.to_categorical(variety_train, num_classes)\n",
    "variety_test = keras.utils.to_categorical(variety_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12040)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          3082496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,082,753\n",
      "Trainable params: 3,082,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# wide model\n",
    "bow_inputs = layers.Input(shape=(vocab_size,)) \n",
    "variety_inputs = layers.Input(shape=(num_classes,))\n",
    "wide_inputs = layers.concatenate([bow_inputs, variety_inputs])\n",
    "wide_inputs = layers.Dense(256, activation='relu')(wide_inputs)\n",
    "predictions = layers.Dense(1)(wide_inputs)\n",
    "wide_model = keras.Model(inputs=[bow_inputs, variety_inputs], outputs=predictions)\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word embeddings for train and test\n",
    "description_embed_train = tokenize.texts_to_sequences(X_train['description'])\n",
    "description_embed_test = tokenize.texts_to_sequences(X_test['description'])\n",
    "\n",
    "max_seq_length = 170\n",
    "description_embed_train = keras.preprocessing.sequence.pad_sequences(description_embed_train,\n",
    "                                                                     maxlen=max_seq_length, padding=\"post\")\n",
    "    \n",
    "description_embed_test = keras.preprocessing.sequence.pad_sequences(description_embed_test, \n",
    "                                                                    maxlen=max_seq_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 170, 8)            96000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1361      \n",
      "=================================================================\n",
      "Total params: 97,361\n",
      "Trainable params: 97,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
    "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = layers.Dense(1)(embedding)\n",
    "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 170)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12040)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 170, 8)       96000       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          3082496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1360)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1361        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,180,117\n",
      "Trainable params: 3,180,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Combine wide and deep into one model\n",
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95646/95646 [==============================] - 81s 852us/step - loss: 1204.0448 - acc: 0.0264\n",
      "Epoch 2/10\n",
      "95646/95646 [==============================] - 79s 829us/step - loss: 927.0129 - acc: 0.0363\n",
      "Epoch 3/10\n",
      "95646/95646 [==============================] - 79s 827us/step - loss: 793.5155 - acc: 0.0402\n",
      "Epoch 4/10\n",
      "95646/95646 [==============================] - 79s 822us/step - loss: 675.1074 - acc: 0.0442\n",
      "Epoch 5/10\n",
      "95646/95646 [==============================] - 78s 814us/step - loss: 565.7189 - acc: 0.0483\n",
      "Epoch 6/10\n",
      "95646/95646 [==============================] - 78s 810us/step - loss: 465.2306 - acc: 0.0525\n",
      "Epoch 7/10\n",
      "95646/95646 [==============================] - 79s 825us/step - loss: 374.3860 - acc: 0.0599\n",
      "Epoch 8/10\n",
      "95646/95646 [==============================] - 78s 821us/step - loss: 294.0446 - acc: 0.0674\n",
      "Epoch 9/10\n",
      "95646/95646 [==============================] - 79s 822us/step - loss: 229.9216 - acc: 0.0753\n",
      "Epoch 10/10\n",
      "95646/95646 [==============================] - 78s 817us/step - loss: 179.0933 - acc: 0.0864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fd3687913c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([description_bow_train, variety_train] + [description_embed_train], y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23912/23912 [==============================] - 7s 278us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[631.6691498384703, 0.05206590833428433]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate([description_bow_test, variety_test] + [description_embed_test], y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = combined_model.predict([description_bow_test, variety_test] + [description_embed_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the price, this is not a good effort. It's overoaked and horsey smelling, with a heavy, overripe palate that tastes herbal and like hickory-infused blackberry. Flat and stewy on the finish.\n",
      "Predicted:  22.975567 Actual:  29.0 \n",
      "\n",
      "Here's a 100% Cab that shows the elegance of Napa and the heat of the vintage. The tannins are especially wonderful, being soft, sweet and complicated, giving the wine great structure. But the blackberry, cherry, cassis and chocolate fruit is so overwhelming, it robs the wine of the subtlety desired.\n",
      "Predicted:  92.36188 Actual:  75.0 \n",
      "\n",
      "Always dark in color and flavor profile, Craggy Range stays true to those traits with an excellent 2008 from its own Te Muna Road Vineyard. Hints of cocoa, dried herb and leather accent vibrant black cherry and plum flavors, while the tannins are silky and refined. Drink now–2015.\n",
      "Predicted:  42.84418 Actual:  39.0 \n",
      "\n",
      "A good Cabernet, rough and tannic, with blackberry and blueberry fruit flavors that finish a bit sweet and syrupy.\n",
      "Predicted:  19.20014 Actual:  30.0 \n",
      "\n",
      "Big, rich, dense wine, packed with dark tannins and blackberry fruits. The wine has concentration, layering wood aging with youthful acidity that shines through the structure. An impressive wine that needs aging for at least five years.\n",
      "Predicted:  59.09649 Actual:  35.0 \n",
      "\n",
      "Comes down on the heavy, full-bodied side for Pinot Noir, with plenty of cherry, pomegranate and persimmon flavors. Sweetened with toasty oak, there's also a spicy sandalwood richness that brings an exotic note. Doesn't seem likely to improve, so drink up.\n",
      "Predicted:  44.3412 Actual:  40.0 \n",
      "\n",
      "Plenty of mocha and vanilla combined with racy berry aromas give this an ice cream sundae-type of bouquet. The palate is healthy and snappy, with lively acidity pushing black cherry and meaty plum flavors. Whole and toasty on the finish, with touches of excellence throughout. Impressive for a first effort, with room to improve. Drink now through 2012.\n",
      "Predicted:  48.373116 Actual:  40.0 \n",
      "\n",
      "There's 5% Cabernet Franc in this Temp, which makes all the difference, bringing greater body and tannins to a variety that, on its own, can be simple. The cherry, cola and licorice flavors are accented with a touch of sandalwood, making for a lovely, medium-bodied red wine to drink now.\n",
      "Predicted:  42.06175 Actual:  42.0 \n",
      "\n",
      "Exuberant on the nose with aromas of ripe red cherries, peppery spices, herbs and just a touch of funky earth tones, there's a pleasurable rusticity to this Cabernet Franc. It's boldly structured with rich body and dense, drying tannins that hug the finish. It's lovely now, but should continue to evolve well over the next 3-5 years.\n",
      "Predicted:  77.43345 Actual:  17.0 \n",
      "\n",
      "After a touch of funky reduction, beautiful hints of herbs appear: yarrow and lemon balm play alongside lemon and crisp green-apple aromas. On the palate, these notions all remain taut along a very linear, slender but concentrated body that owes more to citrus than to apples. There is a powerful enduring core of fruit and stone that will make this last. The flavors echo long and leave the mouth totally clean. Drink now through 2035.\n",
      "Predicted:  45.47833 Actual:  44.0 \n",
      "\n",
      "Sweet on the bouquet, although there's a bit of a lactic note. The palate is bright and fruity, but the feel is narrow and goes hard with the tannins. Finishes mildly grabby but it's fruity throughout. A good effort but a little challenging. Can you tell that it has its contradictions?\n",
      "Predicted:  50.822437 Actual:  14.0 \n",
      "\n",
      "Steely and mineral, this wine is as crisp and chalky-textured as possible. It is tight, with nervy acidity as well as touches of wood. A more buttery, rounded character is just beginning to show through to fill out the texture.\n",
      "Predicted:  51.566856 Actual:  45.0 \n",
      "\n",
      "The dark honey-gold color leaves no doubt that this wine spent time in oak, but it's well managed and well integrated, allowing the ripe apple and pear to shine alongside fresh aromas of white flowers and orange blossom. Medium bodied, it offers a pleasant hint of coconut on the lengthy finish.\n",
      "Predicted:  43.987587 Actual:  65.0 \n",
      "\n",
      "Comprised of multiple clones from five different vineyards, this exceptional value includes a rich cohesive core of purple fruits, amplified with barrel flavors of toasted coconut and bright spice. Everything is beautifully focused across the full palate, and even after being open for a full 24 hours, the wine tastes fresh and delicious.\n",
      "Predicted:  55.069702 Actual:  29.0 \n",
      "\n",
      "Smooth, deep aromas of berry, spice, earth and minerals are rolled into a pure, harmonious whole. This Cabernet Sauvignon-led blend is racy, clean and layered on the tongue, while oaky flavors of vanilla and cream are backed by ribald blackberry and cassis. The elegant finish is potent and deep. Drink through 2020.\n",
      "Predicted:  74.56803 Actual:  90.0 \n",
      "\n",
      "Rich and ripe in fruit, in the way of many Paso Robles reds. Offers forward blackberry, blueberry and cocoa flavors, sprinkled with pepper, and a few overripe notes of raisin. The alcohol is quite high, but balanced. One minor quibble is excessive softness.\n",
      "Predicted:  37.98263 Actual:  42.0 \n",
      "\n",
      "Rich in fig, gooseberry, lemon and lime, chamomile and spice flavors, this bone-dry wine is impressively deep. It displays an elegance and finesse, as well as a power seldom found in California Sauvignon Blanc.\n",
      "Predicted:  26.771671 Actual:  18.0 \n",
      "\n",
      "Another inky-dark 2005 Marlborough Pinot, Spy Valley's rendition is assertive and plummy, but perhaps lacking a little bit of perfume. Slightly creamy in texture without being particularly lush, it finishes long and clean.\n",
      "Predicted:  11.469747 Actual:  29.0 \n",
      "\n",
      "Aromas of black fruit carry a light oak accent, and overall this is the type of Malbec that will earn more friends than detractors. Kind of hard and tannic in the mouth, with crisp black cherry and raspberry flavors. Clean but tough mouthfeel. Needs a burger or a slice of pizza to cut the tannins.\n",
      "Predicted:  14.925125 Actual:  12.0 \n",
      "\n",
      "Made from 100% Sangiovese, this shows bright berry nuances that are simple and clean. Notes of cherry and raspberry, plus a touch of bitter almond, are recognizable. The palate feels crisp and bright.\n",
      "Predicted:  22.502756 Actual:  10.0 \n",
      "\n",
      "A touch on the sweeter side. A creamy texture and palate full of jammy dark fruit and plum lead into a finish reminiscent of a cherry Jolly Rancher.\n",
      "Predicted:  21.12823 Actual:  22.0 \n",
      "\n",
      "This dark-colored rosé comes from a single vineyard in the village of Dizy. It is certainly dry as its Extra Brut description indicates, but it offers so much ripe red fruitiness that it is also rich and concentrated. There is bright acidity at the end. Drink now.\n",
      "Predicted:  90.19562 Actual:  200.0 \n",
      "\n",
      "This is a big step up in quality from Erbes' one-star bottling this vintage, offering greater intensity, purity and raciness. Aromas of rock dust set the stage for a wine of intense minerality, balanced by sweet flavors of melon and honey. Bergamot and spice notes linger elegantly on the long finish. Imported by Chapin Cellars, LLC.\n",
      "Predicted:  57.768116 Actual:  48.0 \n",
      "\n",
      "Silky smooth and delicate, this comes from a long-standing family-run winery in the heart of the appellation. It's a subtle, floral wine offering layers of dark plum and strawberry. Medium-weight and tangy in acidity, black tea and toffee notes linger on the finish.\n",
      "Predicted:  56.26947 Actual:  30.0 \n",
      "\n",
      "A 100% Cabernet Sauvignon made in small amounts from multiple vineyards, including Beckstoffer Missouri Hopper in Oakville and the Somerston Vineyard on the eastern edges of the Napa Valley. Rich and concentrated in black plum and berry, this is a supple wine that's highlighted by a seasoning of dusty tannins and coconut shavings. The finish is awash in chocolate and cinnamon.\n",
      "Predicted:  100.971924 Actual:  100.0 \n",
      "\n",
      "Dusty, creamy, powdered sugar aromas are nice and easygoing, while the palate has balance and a mouthfeel that caresses solid apple, citrus and peach flavors. Crisp on the finish, with a decent amount of elegance for a $15 wine. Hard to go wrong with this bubbly.\n",
      "Predicted:  16.92623 Actual:  15.0 \n",
      "\n",
      "An aromatically arresting wine with a complex medley of corn silk, cream and an assortment of spices. It's on the lighter side, elegant in its styling, with tart lemony acidity that runs from head to tail and a lingering finish.\n",
      "Predicted:  21.62368 Actual:  45.0 \n",
      "\n",
      "Filippone is a 50-50 blend of Sangiovese and Merlot that is layered tight with aromas of wild berries, blue flower, plush cherry, moist earth and a touch of playful spice. The structure is firm without being hard and the wine would pair with pasta or meat.\n",
      "Predicted:  41.034706 Actual:  40.0 \n",
      "\n",
      "Rose, red berry, baked earth, forest floor and grilled herb aromas lead the nose while the firm palate offers dried black cherry, cake spice and anise. Firm, fine-grained tannins provide the backbone. Drink 2018–2026.\n",
      "Predicted:  53.245262 Actual:  50.0 \n",
      "\n",
      "Shrap, prickly and sweaty smelling, much like Sauvignon Blanc or Spanish Verdejo. The palate is reflective of the nose: grapefruit and passion fruit along with sourness. Herbal and sour on the citric finish.\n",
      "Predicted:  20.647127 Actual:  12.0 \n",
      "\n",
      "Here is a sweet and fragrant dessert wine with aromas of white flower, honey and stone fruit accented by a slightly drying mineral characteristic. Firm, tonic effervescence keeps the palate refreshed even when paired with whipped cream or creamy fruit desserts.\n",
      "Predicted:  11.79628 Actual:  10.0 \n",
      "\n",
      "A blend of Syrah and Braucol from the slopes above Gaillac, this fruity, friendly wine has notes of spice and red berry. It's attractively juicy, with soft tannins, and it's ready to drink now.\n",
      "Predicted:  14.272454 Actual:  16.0 \n",
      "\n",
      "Nose shows a little brambly earthiness. The wine is quite dark in color, but lackluster in its body and  plum flavors. Imported by Foster's Wine Estates Americas.\n",
      "Predicted:  11.284072 Actual:  12.0 \n",
      "\n",
      "You can taste the racy acidity and minerality of the cool Sonoma Coast in this silky, bone-dry Pinot. The cola, cherry, raspberry and spice flavors are pretty and polished. This is a good price for a coastal Pinot of this elegance.\n",
      "Predicted:  23.54391 Actual:  18.0 \n",
      "\n",
      "This isn't the most powerful, impressive Pinot Noir from the Sonoma Coast, but it has a lot going for it. It's bone dry, crisply acidic and elegant on the palate, with a flavor of sour cherry candy that's savory and clean. Drink now.\n",
      "Predicted:  31.516188 Actual:  17.0 \n",
      "\n",
      "This top cuvée made by the Pelvillain family shows typical black Malbec color, and it has an opulent texture that's packed with notes of rich spice, black plum and balanced wood. While the tannins are present, the fruit offers a full, rich character. With its concentration, this will benefit from several years of aging.\n",
      "Predicted:  64.82297 Actual:  54.0 \n",
      "\n",
      "A rich, layered Cabernet, with a deep core of blackberries, black currants and cedar, leading to a long, spicy finish. The key to understanding this wine is its tannins, which are hard and astringent. It may not have the inherent balance for cellaring. Probably best now, but could surprise.\n",
      "Predicted:  62.672474 Actual:  45.0 \n",
      "\n",
      "Pressed blue flower, ripe black-skinned berry, baking spice, tobacco and leather aromas come together on this round, full-bodied wine. The delicious palate offers juicy wild cherry, raspberry jam, vanilla, cinnamon and licorice while pliant, velvety tannins offer elegant support. It deftly combines power and finesse. Drink through 2024.\n",
      "Predicted:  92.6651 Actual:  80.0 \n",
      "\n",
      "Seems like it was picked earlier than most '03s, given the dry tannins and peppery, minty flavors. Still, it has a beautiful structure, classic and refined, with cherry and cocoa flavors and upscale oak. Drink now through 2010.\n",
      "Predicted:  63.967064 Actual:  55.0 \n",
      "\n",
      "The aromas are mildly toasty, but also vibrant with yellow plums, while the flavors are rich and almost sweet-tasting, ranging from caramel to melted butter to exceedingly ripe peaches. The finish is lush and lingering. To be fair, this is a very good wine, it's just that so many other top NZ Chardonnays cost so much less.\n",
      "Predicted:  72.37462 Actual:  75.0 \n",
      "\n",
      "Average prediction difference:  13.785834527015686\n"
     ]
    }
   ],
   "source": [
    "num_predictions = 40\n",
    "diff = 0\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    val = predictions[i]\n",
    "    prediction = val[0]\n",
    "    actual = y_test.iloc[i]\n",
    "    print(X_test['description'].iloc[i])\n",
    "    print('Predicted: ', prediction, 'Actual: ', actual, '\\n')\n",
    "    diff += abs(prediction - actual)\n",
    "\n",
    "print('Average prediction difference: ', diff / num_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
